# app.py
from flask import Flask, render_template, request, jsonify
import chromadb
import uuid
from datetime import datetime
from apscheduler.schedulers.background import BackgroundScheduler
from sentence_transformers import SentenceTransformer
import os
import re
import requests
from flask import Flask, render_template, request, jsonify, session, redirect # redirect ì¶”ê°€
from supabase import create_client, Client
from dotenv import load_dotenv

load_dotenv()
app = Flask(__name__)
app.secret_key = os.environ.get('FLASK_SECRET_KEY', 'e48ca7312db5b8f76c0c095e845c9eaf')
SUPABASE_URL = os.environ.get('SUPABASE_URL')
SUPABASE_KEY = os.environ.get('SUPABASE_KEY')
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)


#
# í•˜ì˜
#
# 1024ì°¨ì› ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
print("ğŸ”„ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
embedding_model = SentenceTransformer('intfloat/multilingual-e5-small')
print(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {embedding_model.get_sentence_embedding_dimension()}ì°¨ì›")

# ChromaDB ì´ˆê¸°í™”
try:
    chroma_client = chromadb.PersistentClient(path="./vectordb_e5small")
    bible_collection = chroma_client.get_collection(name="bible")
    print(f"âœ… ì»¬ë ‰ì…˜ ë¡œë“œ ì„±ê³µ: {bible_collection.name}")
    print(f"   ì´ êµ¬ì ˆ ìˆ˜: {bible_collection.count()}")
except Exception as e:
    print(f"âŒ ChromaDB ì—ëŸ¬: {e}")
    bible_collection = None

# ê²€ìƒ‰ ì£¼ì œë¥¼ ë¬¸ë§¥/ëŒ€í‘œ êµ¬ì ˆê³¼ í•¨ê»˜ í™•ì¥í•˜ê¸° ìœ„í•œ íŒíŠ¸ ì„¸íŠ¸
DEFAULT_CONTEXT_DESCRIPTION = (
    'ìœ„ë¡œì™€ ê²©ë ¤, í•˜ë‚˜ë‹˜ì˜ ì‹ ì‹¤í•˜ì‹¬, íšŒë³µê³¼ ì†Œë§, ë‘ë ¤ì›€ì„ ì´ê¸°ëŠ” ë¯¿ìŒ, ì‚¬ë‘ê³¼ ìš©ê¸°'
)

THEME_CONTEXT_RULES = [
    {
        "tokens": ['ì·¨ì—…', 'ì§„ë¡œ', 'ì§ì¥', 'ì»¤ë¦¬ì–´', 'íšŒì‚¬'],
        "description": 'ì·¨ì—…ê³¼ ì§„ë¡œ, ì¥ë˜ì˜ ê¸¸, í•˜ë‚˜ë‹˜ì˜ ê³µê¸‰ê³¼ ì¸ë„, ë‘ë ¤ì›€ ëŒ€ì‹  ë‹´ëŒ€í•¨',
        "curated_references": [
            "ì ì–¸ 16:3",
            "ì ì–¸ 3:5-6",
            "ì˜ˆë ˆë¯¸ì•¼ 29:11",
            "ì‹œí¸ 37:23",
            "ë¹Œë¦½ë³´ì„œ 4:13",
        ],
    },
    {
        "tokens": ['ì‹œí—˜', 'ê³µë¶€', 'í•™ì—…', 'ì…ì‹œ'],
        "description": 'ì§€í˜œì™€ ì¸ë‚´, ì„±ì‹¤í•˜ê²Œ ì¤€ë¹„í•˜ëŠ” ë§ˆìŒ, í•˜ë‚˜ë‹˜ê»˜ ë§¡ê¸°ëŠ” ë¯¿ìŒ',
        "curated_references": [
            "ì•¼ê³ ë³´ì„œ 1:5",
            "ê³ ë¦°ë„ì „ì„œ 10:13",
            "ë¹Œë¦½ë³´ì„œ 4:6",
            "ë¹Œë¦½ë³´ì„œ 4:13",
            "ì ì–¸ 2:6",
        ],
    },
    {
        "tokens": ['ìœ„ë¡œ', 'ìŠ¬í””', 'ëˆˆë¬¼', 'ìƒì‹¤', 'ì•„í””', 'ê³ í†µ'],
        "description": 'ìœ„ë¡œì™€ íšŒë³µ, í•¨ê»˜í•˜ì‹œëŠ” í•˜ë‚˜ë‹˜, ëˆˆë¬¼ì„ ë‹¦ì•„ì£¼ì‹œëŠ” ì‚¬ë‘',
        "curated_references": [
            "ì‹œí¸ 119:50",
            "ì´ì‚¬ì•¼ 41:10",
            "ì‹œí¸ 34:18",
            "ë§ˆíƒœë³µìŒ 11:28",
            "ì‹œí¸ 147:3",
        ],
    },
    {
        "tokens": ['ì†Œë§', 'í¬ë§', 'ë¯¸ë˜', 'ì¥ë˜'],
        "description": 'ì†Œë§ê³¼ ë¯¸ë˜ì— ëŒ€í•œ ì•½ì†, í•˜ë‚˜ë‹˜ì´ ì˜ˆë¹„í•˜ì‹  ê³„íšì„ ì‹ ë¢°í•¨',
        "curated_references": [
            "ì˜ˆë ˆë¯¸ì•¼ 29:11",
            "ê³ ë¦°ë„ì „ì„œ 13:13",
            "ë¡œë§ˆì„œ 15:13",
            "íˆë¸Œë¦¬ì„œ 11:1",
            "ì‹œí¸ 71:14",
        ],
    },
    {
        "tokens": ['ë‘ë ¤ì›€', 'ê±±ì •', 'ê·¼ì‹¬', 'ë¶ˆì•ˆ'],
        "description": 'ë‘ë ¤ì›€ì„ ì´ê¸°ëŠ” ë¯¿ìŒ, í‰ì•ˆ, ë‹´ëŒ€í•¨, ì—¼ë ¤ë¥¼ ë§¡ê¹€',
        "curated_references": [
            "ì´ì‚¬ì•¼ 41:10",
            "ë¹Œë¦½ë³´ì„œ 4:6-7",
            "ë§ˆíƒœë³µìŒ 6:34",
            "ì‹œí¸ 56:3",
            "ë””ëª¨ë°í›„ì„œ 1:7",
        ],
    },
    {
        "tokens": ['ê°ì‚¬', 'ê¸°ì¨', 'ì°¬ì–‘'],
        "description": 'ê°ì‚¬ì™€ ì°¬ì–‘, ê¸°ì¨ê³¼ ì¦ê±°ì›€, í•˜ë‚˜ë‹˜ì˜ ì„ í•˜ì‹¬',
        "curated_references": [
            "ì‹œí¸ 100:4",
            "ë°ì‚´ë¡œë‹ˆê°€ì „ì„œ 5:18",
            "ì‹œí¸ 16:11",
            "ë¹Œë¦½ë³´ì„œ 4:4",
            "ëŠí—¤ë¯¸ì•¼ 8:10",
        ],
    },
    {
        "tokens": ['ìš©ì„œ', 'ì£„ì±…ê°', 'íšŒê°œ'],
        "description": 'ìš©ì„œì™€ íšŒê°œ, ìƒˆ ë§ˆìŒ, ì€í˜œë¡œ ë‹¤ì‹œ ì‹œì‘í•¨',
        "curated_references": [
            "ìš”í•œì¼ì„œ 1:9",
            "ëˆ„ê°€ë³µìŒ 17:3-4",
            "ì—ë² ì†Œì„œ 4:32",
            "ì‹œí¸ 103:12",
            "ë¯¸ê°€ 7:19",
        ],
    },
    {
        "tokens": ['ì‚¬ë‘', 'ì—°ì• ', 'ê²°í˜¼', 'ë¶€ë¶€', 'ê°€ì •', 'ë¶€ëª¨', 'ìë…€', 'ê°€ì¡±'],
        "description": 'ì‚¬ë‘ê³¼ ì—°í•©, ê°€ì •ê³¼ ê´€ê³„ íšŒë³µ, ì„œë¡œë¥¼ ì„¸ì›Œ ì¤Œ',
        "curated_references": [
            "ê³ ë¦°ë„ì „ì„œ 13:4-7",
            "ìš”í•œì¼ì„œ 4:8",
            "ì—ë² ì†Œì„œ 5:25",
            "ì ì–¸ 17:17",
            "ê³¨ë¡œìƒˆì„œ 3:13",
        ],
    },
    {
        "tokens": ['ìš°ì •', 'ê³µë™ì²´', 'êµíšŒ', 'í˜•ì œ'],
        "description": 'ê³µë™ì²´ì™€ ìš°ì •, ì„œë¡œë¥¼ ê²©ë ¤í•˜ê³  ì„¸ì›Œ ì£¼ëŠ” ê´€ê³„',
        "curated_references": [
            "ìš”í•œë³µìŒ 15:13",
            "ì ì–¸ 17:17",
            "ì ì–¸ 27:17",
            "ìš”í•œë³µìŒ 17:21",
            "íˆë¸Œë¦¬ì„œ 10:24-25"
        ],
    },
    {
        "tokens": ['ì‚¬ëª…', 'í—Œì‹ ', 'ì„¬ê¹€', 'ìˆœì¢…'],
        "description": 'ì‚¬ëª…ê³¼ ìˆœì¢…, í—Œì‹ ê³¼ ì‚¬ë‘ìœ¼ë¡œ ì„¬ê¸°ëŠ” ì‚¶',
        "curated_references": [
            "ìš”í•œë³µìŒ 14:15",
            "ë¡œë§ˆì„œ 12:1",
            "ì‹ ëª…ê¸° 10:12",
            "ë§ˆíƒœë³µìŒ 16:24",
            "ê°ˆë¼ë””ì•„ì„œ 2:20"
        ],
    },
    {
        "tokens": ['ê±´ê°•', 'ì§ˆë³‘', 'ì¹˜ìœ ', 'íšŒë³µ'],
        "description": 'ì¹˜ìœ ì™€ íšŒë³µ, ê°•ê±´í•¨, ì•½í•œ ìë¥¼ ì„¸ìš°ì‹œëŠ” í•˜ë‚˜ë‹˜',
        "curated_references": [
            "ì•¼ê³ ë³´ì„œ 5:15",
            "ì¶œì• êµ½ê¸° 15:26",
            "ì´ì‚¬ì•¼ 53:5",
            "ë§ˆê°€ë³µìŒ 5:34",
            "ì‹œí¸ 41:3"
        ],
    },
    {
        "tokens": ['ì¬ì •', 'ëˆ', 'í•„ìš”', 'ê¶í•', 'ê°€ë‚œ'],
        "description": 'í•„ìš”ë¥¼ ì±„ìš°ì‹œëŠ” í•˜ë‚˜ë‹˜, ê³µê¸‰ê³¼ ë§Œì¡±, ë‚˜ëˆ”ê³¼ ì‹ ë¢°',
        "curated_references": [
            "ë¹Œë¦½ë³´ì„œ 4:19",
            "ë§ˆíƒœë³µìŒ 6:33",
            "íˆë¸Œë¦¬ì„œ 13:5",
            "ì ì–¸ 30:8",
            "ë§ˆíƒœë³µìŒ 6:26",
        ],
    },
    {
        "tokens": ['ê°ˆë“±', 'ë¶„ë…¸', 'ì‹¸ì›€'],
        "description": 'í™”í•´ì™€ ìš©ì„œ, í‰í™”, ì‚¬ë‘ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•¨',
        "curated_references": [
            "ì•¼ê³ ë³´ì„œ 1:19-20",
            "ì ì–¸ 15:1",
            "ì—ë² ì†Œì„œ 4:26",
            "ë§ˆíƒœë³µìŒ 18:15",
            "ì ì–¸ 16:32"
        ],
    },
    {
        "tokens": ['í‰ì•ˆ', 'ì‰¼', 'ì•ˆì‹', 'ìƒ¬ë¡¬'],
        "description": 'í‰ì•ˆê³¼ ì•ˆì‹, í­í’ ê°€ìš´ë°ë„ ì§€í‚¤ì‹œëŠ” í•˜ë‚˜ë‹˜',
        "curated_references": [
            "ìš”í•œë³µìŒ 14:27",
            "ë§ˆíƒœë³µìŒ 11:28",
            "ì‹œí¸ 4:8",
            "ë¹Œë¦½ë³´ì„œ 4:7",
            "ìš”í•œë³µìŒ 16:33"
        ],
    },
]

REFERENCE_SPLIT_PATTERN = re.compile(r'^(.*?)(\d+:\d.*)$')


REFERENCE_INPUT_PATTERN = re.compile(
    r'^\s*([0-9]{0,1}\s*[ê°€-í£A-Za-z]{1,30})\s*([0-9]{1,3})\s*(?:[:ì¥]\s*([0-9]{1,3}))\s*(?:[-â€“â€”~]\s*([0-9]{1,3}))?\s*(?:ì ˆ)?\s*$'
)

BOOK_ABBREVIATIONS = {
    # í•œê¸€ ì•½ì–´
    "ë§ˆ": "ë§ˆíƒœë³µìŒ", "ë§‰": "ë§ˆê°€ë³µìŒ", "ëˆ…": "ëˆ„ê°€ë³µìŒ", "ìš”": "ìš”í•œë³µìŒ",
    "ë¡¬": "ë¡œë§ˆì„œ", "ê³ ì „": "ê³ ë¦°ë„ì „ì„œ", "ê³ í›„": "ê³ ë¦°ë„í›„ì„œ", "ê°ˆ": "ê°ˆë¼ë””ì•„ì„œ",
    "ì—¡": "ì—ë² ì†Œì„œ", "ë¹Œ": "ë¹Œë¦½ë³´ì„œ", "ê³¨": "ê³¨ë¡œìƒˆì„œ", "ì‚´ì „": "ë°ì‚´ë¡œë‹ˆê°€ì „ì„œ",
    "ì‚´í›„": "ë°ì‚´ë¡œë‹ˆê°€í›„ì„œ", "ë”¤ì „": "ë””ëª¨ë°ì „ì„œ", "ë”¤í›„": "ë””ëª¨ë°í›„ì„œ",
    "ì•½": "ì•¼ê³ ë³´ì„œ", "ë²§ì „": "ë² ë“œë¡œì „ì„œ", "ë²§í›„": "ë² ë“œë¡œí›„ì„œ",
    # ì˜ë¬¸ ì•½ì–´(ì†Œë¬¸ì)
    "mt": "ë§ˆíƒœë³µìŒ", "matt": "ë§ˆíƒœë³µìŒ", "mk": "ë§ˆê°€ë³µìŒ", "lk": "ëˆ„ê°€ë³µìŒ",
    "jn": "ìš”í•œë³µìŒ", "rom": "ë¡œë§ˆì„œ", "1th": "ë°ì‚´ë¡œë‹ˆê°€ì „ì„œ", "2th": "ë°ì‚´ë¡œë‹ˆê°€í›„ì„œ",
    "eph": "ì—ë² ì†Œì„œ", "phil": "ë¹Œë¦½ë³´ì„œ", "jas": "ì•¼ê³ ë³´ì„œ",
}

KOREAN_TO_ENGLISH_BOOK = {v: k for k, v in BOOK_NAME_MAP.items()}
FULL_BOOK_TO_ABBREVIATIONS = {}
for abbr, full in BOOK_ABBREVIATIONS.items():
    if re.fullmatch(r"[ê°€-í£0-9]+", abbr):
        FULL_BOOK_TO_ABBREVIATIONS.setdefault(full, []).append(abbr)


def _collect_all_curated_references():
    seen = set()
    refs = []
    for rule in THEME_CONTEXT_RULES:
        for ref in rule.get("curated_references", []):
            if not ref:
                continue
            cleaned = normalize_korean(ref.strip())
            if cleaned not in seen:
                seen.add(cleaned)
                refs.append(cleaned)
    return refs


ALL_CURATED_REFERENCES = _collect_all_curated_references()
REFERENCE_INDEX = {}
REFERENCE_INDEX_LOADED = False
VERSE_LOOKUP_INDEX = {}
VERSE_LOOKUP_INDEX_LOADED = False


def canonical_book_name(book: str) -> str:
    book_key = normalize_korean(book or '').replace(" ", "")
    if not book_key:
        return ''
    if book_key.lower() in BOOK_ABBREVIATIONS:
        return BOOK_ABBREVIATIONS[book_key.lower()]
    if book_key in BOOK_ABBREVIATIONS:
        return BOOK_ABBREVIATIONS[book_key]
    return BOOK_NAME_MAP.get(book_key, book_key)


def parse_reference_input(text: str):
    m = REFERENCE_INPUT_PATTERN.match(normalize_korean(text or ""))
    if not m:
        return None
    book_raw, chapter, verse, verse_end = m.groups()
    book = canonical_book_name(book_raw)
    if not book:
        return None
    return {
        "book": book,
        "chapter": int(chapter),
        "verse": int(verse),
        "verse_end": int(verse_end) if verse_end else None,
    }


def split_reference(reference: str):
    reference = normalize_korean(reference or '').strip()
    reference = reference.split('(')[0].strip()
    if not reference:
        return '', ''
    match = REFERENCE_SPLIT_PATTERN.match(reference)
    if match:
        book_raw = match.group(1).strip()
        remainder = match.group(2).strip()
    else:
        book_raw = reference
        remainder = ''
    book = canonical_book_name(book_raw)
    if remainder:
        remainder = remainder.strip()
        # ë²”ìœ„ê°€ ë¶™ì–´ ìˆìœ¼ë©´ ì‹œì‘ ì ˆë§Œ ì‚¬ìš©
        for sep in ['-', 'â€“', 'â€”', '~']:
            if sep in remainder:
                remainder = remainder.split(sep)[0].strip()
                break
    remainder = remainder.strip()
    return book, remainder


def normalize_reference(reference: str) -> str:
    """êµ¬ì ˆ í‘œì‹œ ë°©ì‹ì´ ì¡°ê¸ˆì”© ë‹¬ë¼ë„ ë¹„êµê°€ ê°€ëŠ¥í•˜ë„ë¡ ì •ê·œí™”."""
    book, remainder = split_reference(reference)
    if book and remainder:
        base = f"{book} {remainder}"
    elif book:
        base = book
    else:
        base = remainder
    return base.replace(" ", "")


def build_reference_label(metadata: dict, document: str) -> str:
    """ë©”íƒ€ë°ì´í„°ì™€ ë³¸ë¬¸ì—ì„œ ì±… ì´ë¦„ + ì¥:ì ˆì„ ì¡°í•©í•´ ì‚¬ëŒì´ ì½ì„ ë ˆí¼ëŸ°ìŠ¤ë¥¼ ë§Œë“ ë‹¤."""
    reference_field = metadata.get("reference") or ""
    source_field = metadata.get("source") or ""
    ref_book, ref_numbers = split_reference(reference_field)
    source_book = canonical_book_name(source_field)
    book = ref_book or source_book
    chapter_verse = extract_chapter_verse(document or "") if document else None

    if not chapter_verse and ref_numbers:
        chapter_verse = ref_numbers

    if book and chapter_verse:
        return f"{book} {chapter_verse}"
    if book:
        return book
    if chapter_verse:
        return chapter_verse
    return "ì•Œ ìˆ˜ ì—†ëŠ” êµ¬ì ˆ"


def build_reference_index():
    """í…Œë§ˆ ëŒ€í‘œ êµ¬ì ˆì„ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ ë©”ëª¨ë¦¬ì— ì ì¬."""
    global REFERENCE_INDEX_LOADED
    if REFERENCE_INDEX_LOADED or not bible_collection or not ALL_CURATED_REFERENCES:
        REFERENCE_INDEX_LOADED = True
        return

    target_refs = {
        normalize_reference(ref): ref
        for ref in ALL_CURATED_REFERENCES
        if ref
    }
    target_refs.pop('', None)

    if not target_refs:
        REFERENCE_INDEX_LOADED = True
        return

    print("ğŸ”„ í…Œë§ˆ ëŒ€í‘œ êµ¬ì ˆ ì¸ë±ìŠ¤ ë¡œë”© ì¤‘...")
    try:
        data = bible_collection.get(include=["documents", "metadatas"])
    except Exception as e:
        print(f"âš ï¸ ëŒ€í‘œ êµ¬ì ˆ ì¸ë±ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
        return

    docs = data.get("documents") or []
    metas = data.get("metadatas") or []
    found = 0

    for doc, meta in zip(docs, metas):
        reference = build_reference_label(meta, doc)
        normalized = normalize_reference(reference)
        if normalized in target_refs and normalized not in REFERENCE_INDEX:
            REFERENCE_INDEX[normalized] = {
                "text": doc,
                "metadata": meta,
            }
            found += 1
            if found == len(target_refs):
                break

    REFERENCE_INDEX_LOADED = True
    print(f"âœ… ëŒ€í‘œ êµ¬ì ˆ ì¸ë±ìŠ¤ ì¤€ë¹„ ì™„ë£Œ: {len(REFERENCE_INDEX)}ê°œ ë§¤í•‘")


def ensure_reference_index():
    if not REFERENCE_INDEX_LOADED and bible_collection:
        build_reference_index()


def build_verse_lookup_index():
    """(ì±…+ì¥:ì ˆ) â†’ ë¬¸ì„œ ì „ì²´ ì¸ë±ìŠ¤"""
    global VERSE_LOOKUP_INDEX_LOADED
    if VERSE_LOOKUP_INDEX_LOADED or not bible_collection:
        VERSE_LOOKUP_INDEX_LOADED = True
        return
    for doc, meta in iter_collection_documents(include=["documents", "metadatas"]):
        ref = build_reference_label(meta, doc)
        key = normalize_reference(ref)
        if key and key not in VERSE_LOOKUP_INDEX:
            VERSE_LOOKUP_INDEX[key] = {"text": doc, "metadata": meta}
    VERSE_LOOKUP_INDEX_LOADED = True


def ensure_verse_lookup_index():
    if not VERSE_LOOKUP_INDEX_LOADED and bible_collection:
        build_verse_lookup_index()


VERSE_LOOKUP_INDEX = {}
VERSE_LOOKUP_INDEX_LOADED = False


def iter_collection_documents(where=None, include=None, batch_size=2000):
    include = include or ["documents", "metadatas"]
    offset = 0
    while True:
        try:
            data = bible_collection.get(
                where=where,
                include=include,
                limit=batch_size,
                offset=offset,
            )
        except TypeError:
            data = bible_collection.get(where=where, include=include)
        docs = data.get("documents") or []
        metas = data.get("metadatas") or []
        if not docs:
            return
        for d, m in zip(docs, metas):
            yield d, (m or {})
        offset += len(docs)


def build_verse_lookup_index():
    global VERSE_LOOKUP_INDEX_LOADED
    if VERSE_LOOKUP_INDEX_LOADED or not bible_collection:
        VERSE_LOOKUP_INDEX_LOADED = True
        return

    for doc, meta in iter_collection_documents(include=["documents", "metadatas"]):
        ref = build_reference_label(meta, doc)
        key = normalize_reference(ref)
        if key and key not in VERSE_LOOKUP_INDEX:
            VERSE_LOOKUP_INDEX[key] = {"text": doc, "metadata": meta}

    VERSE_LOOKUP_INDEX_LOADED = True


def ensure_verse_lookup_index():
    if not VERSE_LOOKUP_INDEX_LOADED and bible_collection:
        build_verse_lookup_index()


def extract_exact_verse_text(book, chapter, verse, document):
    doc_norm = normalize_korean(document or "")
    abbrs = FULL_BOOK_TO_ABBREVIATIONS.get(book, [])
    for abbr in abbrs:
        start = re.search(
            rf'{re.escape(abbr)}\s*{chapter}\s*:\s*{verse}\s*',
            doc_norm,
        )
        if not start:
            continue
        nxt = re.search(
            r'\n?\s*[ê°€-í£]{1,5}\s*\d+\s*:\s*\d+\s*',
            doc_norm[start.end():],
        )
        end_idx = start.end() + (nxt.start() if nxt else len(doc_norm))
        body = doc_norm[start.end():end_idx].strip()
        return f"{abbr}{chapter}:{verse} {body}".strip()
    return None


def get_exact_verse_entry(ref_input: str):
    parsed = parse_reference_input(ref_input)
    if not parsed:
        return None

    book = parsed["book"]
    chapter = parsed["chapter"]
    verse = parsed["verse"]
    target_label = f"{book} {chapter}:{verse}"
    target_key = normalize_reference(target_label)

    ensure_verse_lookup_index()
    if target_key in VERSE_LOOKUP_INDEX:
        return VERSE_LOOKUP_INDEX[target_key]

    def doc_has_target(doc: str):
        doc_compact = re.sub(r"\s+", "", normalize_korean(doc or ""))
        markers = [
            f"{abbr}{chapter}:{verse}"
            for abbr in FULL_BOOK_TO_ABBREVIATIONS.get(book, [])
        ]
        markers += [re.sub(r"\s+", "", f"{book} {chapter}:{verse}")]
        return any(m in doc_compact for m in markers if m)

    for src in [book, KOREAN_TO_ENGLISH_BOOK.get(book)]:
        if not src:
            continue
        for doc, meta in iter_collection_documents(
            where={"source": src},
            include=["documents", "metadatas"],
        ):
            if normalize_reference(build_reference_label(meta, doc)) == target_key:
                return {"text": doc, "metadata": meta}
            if doc_has_target(doc):
                text = extract_exact_verse_text(book, chapter, verse, doc) or doc
                meta = dict(meta or {})
                meta["_reference_override"] = target_label
                return {"text": text, "metadata": meta}

    try:
        emb = embedding_model.encode(f"{target_label} ì„±ê²½ êµ¬ì ˆ").tolist()
        res = bible_collection.query(
            query_embeddings=[emb],
            n_results=200,
            include=["documents", "metadatas", "distances"],
        )
        docs = (res.get("documents") or [[]])[0]
        metas = (res.get("metadatas") or [[]])[0]
        for doc, meta in zip(docs, metas):
            if normalize_reference(build_reference_label(meta, doc)) == target_key:
                return {"text": doc, "metadata": meta}
            if doc_has_target(doc):
                text = extract_exact_verse_text(book, chapter, verse, doc) or doc
                meta = dict(meta or {})
                meta["_reference_override"] = target_label
                return {"text": text, "metadata": meta}
    except Exception:
        pass

    return None


def get_or_create_curated_entry(normalized_key: str, reference_label: str):
    if not normalized_key:
        return None
    cached = REFERENCE_INDEX.get(normalized_key)
    if cached:
        return cached
    hit = get_exact_verse_entry(reference_label)
    if hit:
        REFERENCE_INDEX[normalized_key] = hit
        return hit
    return None


postboxes = {}
postcards = {}

# í…œí”Œë¦¿ ìœ í˜• ë§¤í•‘ (Supabase templates.template_type: 0=ì—½ì„œ, 1=í¸ì§€ì§€)
TEMPLATE_TYPE_MAP = {
    "ì—½ì„œ": 0,
    "í¸ì§€ì§€": 1,
}


def supabase_headers():
    return {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json",
    }


def fetch_postbox_supabase(postbox_id: str):
    if not SUPABASE_URL or not SUPABASE_KEY:
        return None
    endpoint = f"{SUPABASE_URL.rstrip('/')}/rest/v1/postboxes"
    params = {"id": f"eq.{postbox_id}", "limit": 1}
    try:
        resp = requests.get(endpoint, headers=supabase_headers(), params=params, timeout=8)
        if resp.status_code != 200:
            print(f"âš ï¸ Supabase post fetch ì‹¤íŒ¨ status={resp.status_code}, body={resp.text}")
            return None
        data = resp.json()
        return data[0] if data else None
    except Exception as exc:
        print(f"âš ï¸ Supabase post fetch ì˜ˆì™¸: {exc}")
        return None


def fetch_postcards_supabase(postbox_id: str):
    if not SUPABASE_URL or not SUPABASE_KEY:
        return []
    endpoint = f"{SUPABASE_URL.rstrip('/')}/rest/v1/postcards"
    params = {"postbox_id": f"eq.{postbox_id}", "order": "created_at.asc"}
    try:
        resp = requests.get(endpoint, headers=supabase_headers(), params=params, timeout=8)
        if resp.status_code != 200:
            print(f"âš ï¸ Supabase postcards fetch ì‹¤íŒ¨ status={resp.status_code}, body={resp.text}")
            return []
        return resp.json() or []
    except Exception as exc:
        print(f"âš ï¸ Supabase postcards fetch ì˜ˆì™¸: {exc}")
        return []




def fetch_postcard_by_id(postcard_id: str):
    """ìš°í¸ IDë¡œ ì—½ì„œ 1ê±´ì„ ê°€ì ¸ì˜¨ë‹¤ (ë©”ëª¨ë¦¬ ìºì‹œ â†’ Supabase)."""
    # 1) ë©”ëª¨ë¦¬ ìºì‹œ ìš°ì„ 
    for plist in postcards.values():
        for card in plist:
            if card.get("id") == postcard_id:
                return card

    # 2) Supabase ì¡°íšŒ
    if SUPABASE_URL and SUPABASE_KEY:
        endpoint = f"{SUPABASE_URL.rstrip('/')}/rest/v1/postcards"
        params = {"id": f"eq.{postcard_id}", "limit": 1}
        try:
            resp = requests.get(endpoint, headers=supabase_headers(), params=params, timeout=8)
            if resp.status_code == 200:
                data = resp.json() or []
                return data[0] if data else None
            else:
                print(f"âš ï¸ Supabase postcard fetch ì‹¤íŒ¨ status={resp.status_code}, body={resp.text}")
        except Exception as exc:
            print(f"âš ï¸ Supabase postcard fetch ì˜ˆì™¸: {exc}")
    return None


def store_postbox_supabase(postbox: dict):
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âš ï¸ Supabase ì„¤ì •ì´ ì—†ì–´ postboxes ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    endpoint = f"{SUPABASE_URL.rstrip('/')}/rest/v1/postboxes"
    headers = supabase_headers()
    headers["Prefer"] = "return=representation"
    payload = {
        "id": postbox["id"],
        "name": postbox.get("name"),
        "prayer_topic": postbox.get("prayer_topic", ""),
        "url": postbox.get("url"),
        "created_at": postbox.get("created_at"),
        "is_opened": postbox.get("is_opened", False),
    }
    try:
        resp = requests.post(endpoint, headers=headers, json=payload, timeout=8)
        if resp.status_code not in (200, 201):
            print(f"âš ï¸ Supabase postboxes ì €ì¥ ì‹¤íŒ¨ status={resp.status_code}, body={resp.text}")
            return None
        return resp.json()
    except Exception as exc:
        print(f"âš ï¸ Supabase postboxes ì €ì¥ ì˜ˆì™¸: {exc}")
        return None


def ensure_postbox_supabase(postbox_id: str):
    """Supabase postboxesì— í•´ë‹¹ postboxê°€ ì—†ìœ¼ë©´ ì €ì¥ì„ ì‹œë„."""
    if not SUPABASE_URL or not SUPABASE_KEY:
        return
    if fetch_postbox_supabase(postbox_id):
        return
    pb = postboxes.get(postbox_id)
    if pb:
        store_postbox_supabase(pb)


def store_postcard_supabase(postbox_id: str, postcard: dict):
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âš ï¸ Supabase ì„¤ì •ì´ ì—†ì–´ postcards ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    # ì™¸ë˜í‚¤ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ postbox ë ˆì½”ë“œ í™•ë³´
    ensure_postbox_supabase(postbox_id)
    endpoint = f"{SUPABASE_URL.rstrip('/')}/rest/v1/postcards"
    headers = supabase_headers()
    headers["Prefer"] = "return=representation"
    # template_idë¥¼ integerë¡œ ë³€í™˜ ì‹œë„ (ë¬¸ìì—´ì— ìˆ«ìê°€ ì„ì—¬ ìˆìœ¼ë©´ ìˆ«ìë§Œ ì¶”ì¶œ)
    tpl_id_raw = postcard.get("template_id")
    tpl_id = None
    try:
        if isinstance(tpl_id_raw, str):
            digits = ''.join(ch for ch in tpl_id_raw if ch.isdigit())
            tpl_id = int(digits) if digits else None
        elif tpl_id_raw is not None:
            tpl_id = int(tpl_id_raw)
    except Exception:
        tpl_id = None
    tpl_type_raw = postcard.get("template_type")
    tpl_type = TEMPLATE_TYPE_MAP.get(tpl_type_raw, tpl_type_raw if isinstance(tpl_type_raw, int) else None)
    payload = {
        "id": postcard["id"],
        "postbox_id": postbox_id,
        "template_id": tpl_id,
        "template_type": tpl_type,
        "is_anonymous": postcard.get("is_anonymous", False),
        "verse_reference": postcard.get("verse_reference"),
        "verse_text": postcard.get("verse_text"),
        "message": postcard.get("message", ""),
        "created_at": postcard.get("created_at"),
    }
    if postcard.get("font_family"):
        payload["font_family"] = postcard.get("font_family")
    if postcard.get("font_style"):
        payload["font_style"] = postcard.get("font_style")
    try:
        resp = requests.post(endpoint, headers=headers, json=payload, timeout=8)
        if resp.status_code in (200, 201):
            return resp.json()
        if resp.status_code == 400 and ("font_family" in resp.text or "font_style" in resp.text):
            fallback_payload = dict(payload)
            fallback_payload.pop("font_family", None)
            fallback_payload.pop("font_style", None)
            resp_font_retry = requests.post(endpoint, headers=headers, json=fallback_payload, timeout=8)
            if resp_font_retry.status_code in (200, 201):
                print("â„¹ï¸ Supabaseê°€ ê¸€ì”¨ì²´ ì»¬ëŸ¼ì„ ì§€ì›í•˜ì§€ ì•Šì•„ ê¸°ë³¸ í•„ë“œë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                return resp_font_retry.json()
        # ì™¸ë˜í‚¤ ë¶€ì¡± ë“±ìœ¼ë¡œ ì‹¤íŒ¨í•˜ë©´ í•œë²ˆ ë” postbox upsert ì‹œë„ í›„ ì¬ì‹œë„
        if resp.status_code == 409:
            ensure_postbox_supabase(postbox_id)
            resp_retry = requests.post(endpoint, headers=headers, json=payload, timeout=8)
            if resp_retry.status_code in (200, 201):
                return resp_retry.json()
            print(f"âš ï¸ Supabase postcards ì¬ì‹œë„ ì‹¤íŒ¨ status={resp_retry.status_code}, body={resp_retry.text}")
        else:
            print(f"âš ï¸ Supabase postcards ì €ì¥ ì‹¤íŒ¨ status={resp.status_code}, body={resp.text}")
    except Exception as exc:
        print(f"âš ï¸ Supabase postcards ì €ì¥ ì˜ˆì™¸: {exc}")
        return None


@app.route('/view-postcard/<postcard_id>')
def view_postcard(postcard_id):
    card = fetch_postcard_by_id(postcard_id)
    if not card:
        return "ì—½ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 404
    sender = "ìµëª…"
    verse_ref = card.get("verse_reference") or "ë§ì”€"
    verse_text = card.get("verse_text") or ""
    message = card.get("message") or ""
    font_family = card.get("font_family") or ""
    tpl_id_raw = card.get("template_id") or 1
    tpl_img = None
    tpl_type = card.get("template_type") or 0
    try:
        tpl_meta = fetch_template_meta(int(tpl_id_raw))
        if tpl_meta:
            tpl_img = tpl_meta.get("image_path")
            tpl_type = tpl_meta.get("template_type", tpl_type)
    except Exception:
        tpl_meta = None
    # íŒŒì¼ ì‹œìŠ¤í…œì€ ëŒ€ì†Œë¬¸ì êµ¬ë¶„ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì†Œë¬¸ìë¡œ ì •ê·œí™”
    template_image = (tpl_img or "images/postcards/POSTCARD1.png").lower()
    template_type = tpl_type
    return render_template(
        'postcard_view.html',
        postcard_id=postcard_id,
        sender=sender,
        verse_reference=verse_ref,
        verse_text=verse_text,
        message=message,
        font_family=font_family,
        template_id=tpl_id_raw,
        template_type=template_type,
        template_image=template_image,
    )

def store_generated_url(original_url: str, base_url: str):
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âš ï¸ Supabase ì„¤ì •ì´ ì—†ì–´ generated_urls ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    endpoint = f"{SUPABASE_URL.rstrip('/')}/rest/v1/generated_urls"
    headers = supabase_headers()
    headers["Prefer"] = "return=representation"

    last_error = None
    for _ in range(3):
        short_code = uuid.uuid4().hex[:8]
        short_url = f"{base_url.rstrip('/')}/{short_code}"
        payload = {"short_url": short_url, "original_url": original_url}

        try:
            resp = requests.post(endpoint, headers=headers, json=payload, timeout=8)
        except Exception as exc:
            last_error = f"request failure: {exc}"
            break

        if resp.status_code in (200, 201):
            try:
                data = resp.json()
                if isinstance(data, list) and data:
                    return data[0].get("short_url", short_url)
                if isinstance(data, dict) and data.get("short_url"):
                    return data.get("short_url")
            except ValueError:
                return short_url
            return short_url

        if resp.status_code == 409:
            last_error = "duplicate short_url, retrying"
            continue

        last_error = f"status={resp.status_code}, body={resp.text}"
        break

    if last_error:
        print(f"âš ï¸ Supabase generated_urls ì €ì¥ ì‹¤íŒ¨: {last_error}")
    return None


def build_contextual_query(keyword: str):
    """í‚¤ì›Œë“œë¥¼ ìƒí™© ì„¤ëª… ë¬¸ì¥ìœ¼ë¡œ í™•ì¥í•˜ê³ , í…Œë§ˆë³„ ëŒ€í‘œ êµ¬ì ˆ ëª©ë¡ë„ í•¨ê»˜ ë°˜í™˜."""
    keyword = (keyword or '').strip()
    lowered = keyword.lower()
    matched_contexts = []
    curated_refs = []

    for rule in THEME_CONTEXT_RULES:
        tokens = rule["tokens"]
        if any(token in keyword for token in tokens) or any(token in lowered for token in tokens):
            matched_contexts.append(rule["description"])
            curated_refs.extend(rule.get("curated_references", []))

    if not matched_contexts:
        matched_contexts.append(DEFAULT_CONTEXT_DESCRIPTION)

    # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ìˆœì„œ ìœ ì§€
    seen_ctx = set()
    unique_contexts = []
    for ctx in matched_contexts:
        if ctx not in seen_ctx:
            unique_contexts.append(ctx)
            seen_ctx.add(ctx)

    seen_refs = set()
    unique_refs = []
    for ref in curated_refs:
        ref = ref.strip()
        if ref and ref not in seen_refs:
            unique_refs.append(ref)
            seen_refs.add(ref)

    contextual_summary = ' / '.join(unique_contexts)
    expanded = (
        f"query: {keyword}. "
        f"ìƒí™©ê³¼ ê°ì •: {contextual_summary}. "
        "ì£¼ì œì™€ ë§ë‹¿ì€ ì„±ê²½ì˜ ì•½ì†, ìœ„ë¡œ, ê²©ë ¤, ë„ì „, í•˜ë‚˜ë‹˜ì˜ ì„±í’ˆê³¼ ê³„íšì„ ì°¾ëŠ”ë‹¤."
    )
    return expanded, unique_refs


KOREAN_STOPWORDS = {
    "ìê¸°",
    "ìš°ë¦¬",
    "ë„ˆí¬",
    "ê·¸",
    "ì´",
    "ì €",
    "ê²ƒ",
    "ìˆ˜",
    "ë•Œ",
    "ë§",
    "ì¼",
    "ì„",
    "ë¥¼",
    "ì´",
    "ê°€",
    "ì€",
    "ëŠ”",
    "ì—",
    "ì˜",
    "ê³¼",
    "ì™€",
    "ë¡œ",
    "ìœ¼ë¡œ",
}


def greedy_terms(q: str):
    terms = []
    for tok in re.findall(
        r"[ê°€-í£]{2,}|[a-z]{2,}",
        normalize_korean(q or "").lower(),
    ):
        if tok in KOREAN_STOPWORDS:
            continue
        terms.append(tok)
    seen = set()
    out = []
    for t in terms:
        if t not in seen:
            out.append(t)
            seen.add(t)
    return out[:6]


def greedy_match_count(terms, doc: str):
    docc = re.sub(r"\s+", "", normalize_korean(doc or "").lower())
    return sum(1 for t in terms if t and re.sub(r"\s+", "", t) in docc)


@app.route('/api/recommend-verses', methods=['POST'])
def recommend_verses():
    """ë ˆí¼ëŸ°ìŠ¤ ì§ì ‘ ë§¤ì¹­ â†’ ë¬¸êµ¬ ê²€ìƒ‰(greedy+semantic) ì¶”ì²œ."""
    if not bible_collection:
        return jsonify({'error': 'ChromaDB ì»¬ë ‰ì…˜ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}), 500
    
    try:
        data = request.get_json(silent=True) or {}
        query = (data.get('query') or data.get('keyword') or '').strip()
        page = 0
        try:
            page = max(0, int(data.get('page', 0)))
        except Exception:
            page = 0
        if not query:
            return jsonify({'error': 'ê²€ìƒ‰ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
        print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
        ensure_reference_index()
        ensure_verse_lookup_index()

        # 1) ë ˆí¼ëŸ°ìŠ¤ ì§ì ‘ ë§¤ì¹­ ë¨¼ì € ì‹œë„
        exact_hit = get_exact_verse_entry(query)
        if exact_hit:
            meta = exact_hit["metadata"] or {}
            ref_override = meta.get("_reference_override")
            if ref_override:
                reference = ref_override
            else:
                reference = build_reference_label(meta, exact_hit["text"])
            print(f"   ğŸ¯ ë ˆí¼ëŸ°ìŠ¤ ì§ì ‘ ë§¤ì¹­ ì„±ê³µ: {reference}")

            return jsonify({
                "success": True, 
                "url": unique_path
            })
        else:
            print("   âš ï¸ ë ˆí¼ëŸ°ìŠ¤ ì§ì ‘ ë§¤ì¹­ ì—†ìŒ â†’ ì‹œë§¨í‹±/greedy ê²€ìƒ‰ìœ¼ë¡œ ì§„í–‰")

        # 2) í…Œë§ˆ í† í° ë§¤ì¹­ â†’ curated êµ¬ì ˆ ìš°ì„  ì£¼ì…
        query_text, curated_refs = build_contextual_query(query)
        curated_set = set()
        curated_items = []
        for ref in curated_refs:
            key = normalize_reference(ref)
            if not key or key in curated_set:
                continue
            curated_set.add(key)
            hit = get_or_create_curated_entry(key, ref)
            if hit:
                meta = hit.get("metadata") or {}
                doc = hit.get("text", "")
                reference = build_reference_label(meta, doc)
                pop = meta.get("popularity", 85)
                curated_items.append({
                    "reference": reference,
                    "text": doc,
                    "metadata": meta,
                    "score": 1.8,
                    "priority": "theme_top",
                    "popularity": pop,
                })
            else:
                print(f"     âš ï¸ ëŒ€í‘œ êµ¬ì ˆ ë¯¸ë°œê²¬: {ref}")
        if curated_items:
            print(f"   ğŸ¯ í…Œë§ˆ ëŒ€í‘œ êµ¬ì ˆ {len(curated_items)}ê°œ ì£¼ì…")

        # 3) ë¬¸êµ¬ ê²€ìƒ‰: greedy + semantic í˜¼í•©
        expanded_terms = greedy_terms(query)
        normalized_query = re.sub(r"\s+", "", normalize_korean(query or "").lower())
        print(f"   ğŸ” greedy í•µì‹¬ì–´: {expanded_terms if expanded_terms else 'ì—†ìŒ'}")
        query_embedding = embedding_model.encode(query_text).tolist()
        raw_results = bible_collection.query(
            query_embeddings=[query_embedding],
            n_results=200,
            include=["documents", "metadatas", "distances"],
        )

        docs = (raw_results.get("documents") or [[]])[0]
        metas = (raw_results.get("metadatas") or [[]])[0]
        dists = (raw_results.get("distances") or [[]])[0]

        scored = []
        for doc, meta, dist in zip(docs, metas, dists):
            if not doc:
                continue
            meta = meta or {}
            reference = meta.get("reference") or build_reference_label(meta, doc)
            if normalize_reference(reference) in curated_set:
                continue
            pop = meta.get("popularity", 0)
            semantic = 1 - dist if dist is not None else 0
            greedy_hits = greedy_match_count(expanded_terms, doc)
            greedy_bonus = min(0.18, greedy_hits * 0.06)
            coverage = greedy_hits / max(1, len(expanded_terms)) if expanded_terms else 0
            phrase_bonus = coverage * 0.1  # í•µì‹¬ì–´ ì»¤ë²„ë¦¬ì§€ ë³´ë„ˆìŠ¤
            if coverage >= 0.99:  # ëª¨ë“  í•µì‹¬ì–´ë¥¼ í¬í•¨í•˜ë©´ ì¶”ê°€ ê°€ì‚°
                phrase_bonus += 0.08
            if normalized_query and normalized_query in re.sub(r"\s+", "", normalize_korean(doc or "").lower()):
                phrase_bonus += 0.06  # ì „ì²´ ë¬¸êµ¬ê°€ ì—°ì†í•´ ë“¤ì–´ìˆìœ¼ë©´ ì¶”ê°€ ë³´ë„ˆìŠ¤
            phrase_bonus = min(0.24, phrase_bonus)
            final_score = semantic * 0.6 + (pop / 100.0) * 0.4 + phrase_bonus + greedy_bonus

            scored.append((final_score, reference, doc, meta))

        scored.sort(key=lambda x: x[0], reverse=True)
        all_candidates_full = curated_items + scored
        page_size = 5
        start_idx = page * page_size
        end_idx = start_idx + page_size
        # ìš”ì²­í•œ í˜ì´ì§€ê¹Œì§€ í•„ìš”í•œ ë§Œí¼ë§Œ ìŠ¬ë¼ì´ìŠ¤
        needed = end_idx
        all_candidates = all_candidates_full[:needed]
        page_slice = all_candidates[start_idx:end_idx]
        total_pages = (len(all_candidates_full) + page_size - 1) // page_size if all_candidates_full else 0

        verses = []
        for entry in page_slice:
            if isinstance(entry, tuple):
                score, reference, doc, meta = entry
            else:
                score = entry.get("score", entry.get("final_score", 1.0))
                reference = entry.get("reference")
                doc = entry.get("text")
                meta = entry.get("metadata", {})

            print(f"  ğŸ“Œ [{reference}] score={round(score,4)}")
            snippet = re.sub(r"\s+", " ", (doc or ""))[:120]
            print(f"     {snippet}...")
            verses.append(
                {
                    "reference": reference,
                    "text": doc,
                    "metadata": meta,
                    "score": score,
                }
            )

        has_more = end_idx < len(all_candidates_full)
        return jsonify({
            "verses": verses,
            "has_more": has_more,
            "total_pages": total_pages,
            "page": page,
        })
    
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"}), 500



def format_results(results):
    """ChromaDB ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    formatted = []
    if results['documents'] and results['documents'][0]:
        for i, doc in enumerate(results['documents'][0]):
            metadata = results['metadatas'][0][i] if results.get('metadatas') else {}
            distance = results['distances'][0][i] if results.get('distances') else 0
            
            reference = build_reference_label(metadata, doc)
            similarity_score = round((1 - distance) * 100, 1)
            popularity = metadata.get('popularity', 30)
            
            formatted.append({
                'text': doc,
                'reference': reference,
                'similarity': similarity_score,
                'popularity': popularity
            })
            
            print(f"  [{reference}] ìœ ì‚¬ë„: {similarity_score}% | ì¸ê¸°ë„: {popularity}")
    
    return formatted


@app.route('/api/send-postcard', methods=['POST'])
def send_postcard():
    data = request.json
    postbox_id = data.get('postbox_id')
    
    if postbox_id not in postboxes:
        loaded = fetch_postbox_supabase(postbox_id)
        if not loaded:
            # Supabaseì—ë„ ì—†ìœ¼ë©´ ìµœì†Œ ì •ë³´ë¡œ ìƒì„± í›„ ì§„í–‰
            base_url = request.url_root.rstrip('/')
            postbox_path = f"/postboxes/{postbox_id}"
            fallback = {
                'id': postbox_id,
                'name': 'ìš°ì²´í†µ',
                'nickname': 'ìš°ì²´í†µ',
                'prayer_topic': '',
                'url': postbox_path,
                'created_at': datetime.now().isoformat(),
                'is_opened': False
            }
            postboxes[postbox_id] = fallback
            postcards[postbox_id] = []
            store_postbox_supabase(fallback)
        else:
            postboxes[postbox_id] = loaded
            postcards[postbox_id] = fetch_postcards_supabase(postbox_id)
    
    postcard = {
        'id': str(uuid.uuid4()),
        'template_id': data.get('template_id') or 1,
        'template_type': data.get('template_type') if data.get('template_type') is not None else 0,
        'template_name': data.get('template_name') or '',
        'is_anonymous': bool(data.get('is_anonymous')),
        'verse_reference': data.get('verse_reference'),
        'verse_text': data.get('verse_text'),
        'message': data.get('message', ''),
        'font_family': data.get('font_family') or '',
        'font_style': data.get('font_style') or '',
        'created_at': datetime.now().isoformat()
    }
    
    postcards[postbox_id].append(postcard)
    store_postcard_supabase(postbox_id, postcard)
    
    return jsonify({'success': True, 'postcard_id': postcard['id']})


@app.route('/send/<postbox_id>/write')
def send_page_write(postbox_id):
    if postbox_id not in postboxes:
        loaded = fetch_postbox_supabase(postbox_id)
        if not loaded:
            # Supabaseì—ë„ ì—†ìœ¼ë©´ ìµœì†Œ ì •ë³´ë¡œ ìƒì„±í•˜ì—¬ ì§„í–‰
            base_url = request.url_root.rstrip('/')
            postbox_path = f"/postboxes/{postbox_id}"
            fallback = {
                'id': postbox_id,
                'name': 'ìš°ì²´í†µ',
                'nickname': 'ìš°ì²´í†µ',
                'prayer_topic': '',
                'url': postbox_path,
                'full_url': f"{base_url}{postbox_path}",
                'created_at': datetime.now().isoformat(),
                'is_opened': False
            }
            postboxes[postbox_id] = fallback
            postcards.setdefault(postbox_id, [])
            store_postbox_supabase(fallback)
        else:
            postboxes[postbox_id] = loaded
            postcards.setdefault(postbox_id, fetch_postcards_supabase(postbox_id))

    template_id = request.args.get('template_id')
    template_type = request.args.get('template_type')
    template_name = request.args.get('template_name')

    return render_template(
        'send_postcard.html',
        postbox_id=postbox_id,
        template_id=template_id,
        template_type=template_type,
        template_name=template_name,
    )


@app.route('/send/<postbox_id>/preview')
def send_page_preview(postbox_id):
    if postbox_id not in postboxes:
        loaded = fetch_postbox_supabase(postbox_id)
        if not loaded:
            base_url = request.url_root.rstrip('/')
            postbox_path = f"/postboxes/{postbox_id}"
            fallback = {
                'id': postbox_id,
                'name': 'ìš°ì²´í†µ',
                'nickname': 'ìš°ì²´í†µ',
                'prayer_topic': '',
                'url': postbox_path,
                'full_url': f"{base_url}{postbox_path}",
                'created_at': datetime.now().isoformat(),
                'is_opened': False
            }
            postboxes[postbox_id] = fallback
            postcards.setdefault(postbox_id, [])
            store_postbox_supabase(fallback)
        else:
            postboxes[postbox_id] = loaded
            postcards.setdefault(postbox_id, fetch_postcards_supabase(postbox_id))

    return render_template('preview_postcard.html', postbox_id=postbox_id)


def open_all_postboxes():
    for postbox_id in postboxes:
        postboxes[postbox_id]['is_opened'] = True


# -----------------------
#
# ì„¸ë¦¼
#

@app.route('/auth/check-and-save', methods=['POST'])
def check_and_save():

    data = request.get_json()
    token = data.get('token')
    email = data.get('email')

    try:
        # 1. í† í° ê²€ì¦ (Supabase Auth ì—°ë™)
        user_info = supabase.auth.get_user(token)
        if not user_info:
            return jsonify({"success": False, "message": "ìœ íš¨í•˜ì§€ ì•Šì€ í† í°"}), 401

        # Supabase ìœ ì € ë©”íƒ€ë°ì´í„°ì—ì„œ display_name ì¶”ì¶œ
        user_metadata = user_info.user.user_metadata
        nickname = user_metadata.get('display_name') or user_metadata.get('full_name') or email.split('@')[0]
        
        # 2. bible_users í…Œì´ë¸”ì— Upsert (ì—†ìœ¼ë©´ ìƒì„±, ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸)
        # email ì»¬ëŸ¼ì´ Primary Keyë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        user_data = {
            "email": email,
            "nickname" : nickname,
            "last_login_at": datetime.now().isoformat() # íŒŒì´ì¬ì—ì„œ ì‹œê°„ ìƒì„±
        }
        
        # upsertëŠ” ê¸°ë³¸ì ìœ¼ë¡œ on_conflictë¥¼ Primary Keyë¡œ ì¡ìŠµë‹ˆë‹¤.
        response = supabase.table('bible_users').upsert(user_data).execute()

        if not response.data:
            return jsonify({"success": False, "message": "ìœ ì € ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        user = response.data[0]
        user_id = user.get('id')
        user_flag = user.get('flag', False) # flag ê°’ í™•ì¸ (True/False)
        
        # ì„¸ì…˜ì— ì´ë©”ì¼ ì €ì¥ (ë¡œê·¸ì¸ ìœ ì§€ìš©)
        session['user_email'] = email
        session['user_nickname'] = nickname


        # 2. ë¡œì§ ë¶„ê¸°
        if user_flag:
            # [Case: flag=true] ìš°ì²´í†µ ì •ë³´ ì¡°íšŒ
            postbox_res = supabase.table('postboxes').select('url').eq('owner_id', user_id).execute()
            
            if postbox_res.data:
                # ìš°ì²´í†µ URLì´ ì¡´ì¬í•˜ë©´ í•´ë‹¹ ì£¼ì†Œë¡œ ì•ˆë‚´
                postbox_url = postbox_res.data[0].get('url')
                print(f"Redirecting to: /postbox/{postbox_url}")
                return jsonify({
                    "success": True,
                    "redirect_url": f"/postbox/{postbox_url}", # ì‹¤ì œ ìš°ì²´í†µ ì£¼ì†Œ
                    "status": "existing_user",
                    "nickname": nickname
                })
            else:
                        # ë°ì´í„° ì •í•©ì„± ë°©ì–´: flagëŠ” trueì¸ë° postboxê°€ ì—†ëŠ” ê²½ìš°
                        return jsonify({"success": True, "redirect_url": "/create-postbox", "status": "new_user"})
            
        else:
                    # [Case: flag=false] ê³„ì •ì€ ìˆìœ¼ë‚˜ ìš°ì²´í†µì€ ì—†ìŒ -> ìƒì„± í˜ì´ì§€ë¡œ
                    return jsonify({
                        "success": True, 
                        "redirect_url": "/create-postbox", 
                        "status": "new_user",
                        "nickname": nickname
                    })
    except Exception as e:
        print(f"Error: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


import uuid

@app.route('/create-postbox-action', methods=['POST'])
def create_postbox_action():
    if 'user_email' not in session:
        return jsonify({"success": False, "message": "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 401

    data = request.get_json()
    
    try:
        # ê³ ìœ  URL ìƒì„± (ì˜ˆ: nickname-4ìë¦¬ìˆ«ì)
        unique_path = f"{str(uuid.uuid4())[:8]}" 
        
        postbox_data = {
            "owner_id": data.get('owner_id'),
            "name": data.get('name'),
            "prayer_topic": data.get('prayer_topic'),
            "color": data.get('color'),
            "privacy": data.get('privacy'), # True/False
            "url": unique_path,
            "is_opened": False,
            "created_at" : datetime.now().isoformat()
        }

        # DBì— ì €ì¥ (ì´ë•Œ SQLì—ì„œ ë§Œë“  íŠ¸ë¦¬ê±°ê°€ bible_usersì˜ flagë¥¼ trueë¡œ ë°”ê¿ˆ)
        result = supabase.table('postboxes').insert(postbox_data).execute()

        if result.data:
            return jsonify({
                "success": True, 
                "url": unique_path
            })
        else:
            return jsonify({"success": False, "message": "DB ì €ì¥ ì‹¤íŒ¨"}), 500
    except Exception as e:
        print(f"Create Error: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route('/create-postbox')
def create_postbox_page():
    if 'user_email' not in session:
        return redirect('/')
    
    user_nickname = session.get('user_nickname', 'ì‚¬ìš©ì')

    return render_template('create_postbox.html',
                           user_name=user_nickname,
                           supabase_url=os.environ.get('SUPABASE_URL'), 
                           supabase_key=os.environ.get('SUPABASE_KEY')
                           )

# ìš°ì²´í†µ í™•ì¸
@app.route('/postbox/<url_path>')
def view_postbox(url_path):
    try:
        # 1. DBì˜ 'postboxes' í…Œì´ë¸”ì—ì„œ url ì»¬ëŸ¼ì´ url_pathì™€ ì¼ì¹˜í•˜ëŠ” ë°ì´í„° ì¡°íšŒ
        result = supabase.table('postboxes').select("*").eq("url", url_path).execute()

        # 2. ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° (ì˜ëª»ëœ ì£¼ì†Œ)
        if not result.data:
            print(f"No postbox found in DB for URL: {url_path}")
            return "ìš°ì²´í†µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 404

        postbox = result.data[0] # ì²« ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°

       # 2. í˜„ì¬ ì ‘ì†ìê°€ ì£¼ì¸ì¸ì§€ í™•ì¸ (ì„¸ì…˜ ê¸°ë°˜)
        # ì„¸ì…˜ì˜ ì´ë©”ì¼ê³¼ DBì˜ owner_id(ë˜ëŠ” ì—°ë™ëœ ì´ë©”ì¼)ë¥¼ ë¹„êµ
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ì„¸ì…˜ ì´ë©”ì¼ì´ ìˆê³ , í•´ë‹¹ ìœ ì €ì˜ idì™€ pb['owner_id']ê°€ ê°™ì€ì§€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.
        # ì¼ë‹¨ì€ ë¡œê·¸ì¸ ê¸°ëŠ¥ì„ ê³ ë ¤í•´ ì•„ë˜ì™€ ê°™ì´ êµ¬ì„±í•©ë‹ˆë‹¤.
        user_email = session.get('user_email')
        end_date = session.get('end_date') or '2026-01-01'
        is_owner = False
        
        # ì£¼ì¸ì„ í™•ì¸í•˜ê¸° ìœ„í•´ í˜„ì¬ ë¡œê·¸ì¸ëœ ìœ ì €ì˜ UUIDë¥¼ ê°€ì ¸ì™€ì•¼ í•¨
        if user_email:
            user_res = supabase.table('bible_users').select("id").eq("email", user_email).execute()
            if user_res.data and user_res.data[0]['id'] == postbox['owner_id']:
                is_owner = True

        # 3. ê°œë´‰ì¼ ì„¤ì • (ì˜ˆ: 2026ë…„ 1ì›” 1ì¼)
        from datetime import datetime
        try:
            target_dt = datetime.strptime(end_date, '%Y-%m-%d')
        except:
            # ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ë°©ì–´ ì½”ë“œ
            target_dt = datetime(2026, 1, 1)

        is_expired = datetime.now() >= target_dt

        # 4. í…œí”Œë¦¿ ë Œë”ë§ (HTMLì—ì„œ ì‚¬ìš©í•˜ëŠ” ë³€ìˆ˜ëª…ê³¼ ì¼ì¹˜ì‹œí‚´)
        return render_template('view_postbox.html', 
                               postbox_name=postbox['name'],
                               color=postbox['color'],
                               # DBê°€ 0ì´ë©´ 'public', 1ì´ë©´ 'private'ìœ¼ë¡œ ë³€í™˜í•´ì„œ ì „ë‹¬
                               privacy='public' if postbox['privacy'] == 0 else 'private',
                               end_date=end_date,
                               is_owner=is_owner,
                               is_expired=is_expired)

    except Exception as e:
        print(f"Error: {e}")
        return "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", 500

# í¸ì§€ ì‘ì„±
@app.route('/send_postcard/<url_path>')
def send_postcard(url_path):
    # 1. ë¡œê·¸ì¸ ì²´í¬
    if 'user_email' not in session:
        return redirect('/login')

    # 2. ìš°ì²´í†µ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì‘ì„± í™”ë©´ ê¾¸ë¯¸ê¸°ìš©)
    result = supabase.table('postboxes').select("name, color").eq("url", url_path).execute()
    if not result.data:
        return "ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìš°ì²´í†µì…ë‹ˆë‹¤.", 404

    pb = result.data[0]
    return render_template('send_postcard.html', 
                           url_path=url_path, 
                           postbox_name=pb['name'], 
                           color=pb['color'])


@app.route('/')
def index():
    if 'user_email' in session:
            # ë¡œê·¸ì¸ ì„¸ì…˜ì´ ìˆë‹¤ë©´ DBì—ì„œ flagë¥¼ ë‹¤ì‹œ í™•ì¸
            email = session['user_email']
            user_res = supabase.table('bible_users').select("id, flag").eq("email", email).execute()
            
            if user_res.data and user_res.data[0]['flag'] is True:
                # ìš°ì²´í†µì´ ì´ë¯¸ ìˆë‹¤ë©´ ë‚´ ìš°ì²´í†µìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
                pb_res = supabase.table('postboxes').select("url").eq("owner_id", user_res.data[0]['id']).execute()
                if pb_res.data:
                    return redirect(f"/postbox/{pb_res.data[0]['url']}")
            
            # flagê°€ falseë©´ ìƒì„± í˜ì´ì§€ë¡œ
            return redirect('/create-postbox')
    return render_template('index.html',
                            url=os.environ.get('SUPABASE_URL'), 
                            key=os.environ.get('SUPABASE_KEY'))



scheduler = BackgroundScheduler()
scheduler.add_job(
    func=open_all_postboxes,
    trigger='cron',
    year=2026,
    month=1,
    day=1,
    hour=0,
    minute=0
)
scheduler.start()


if __name__ == '__main__':
    print("\n" + "="*50)
    print("ğŸš€ Flask ì„œë²„ ì‹œì‘")
    print("âœ… ì¸ê¸°ë„ í•„í„°ë§ í™œì„±í™” (3-tier ê²€ìƒ‰)")
    ensure_reference_index()
    ensure_verse_lookup_index()
    # í™˜ê²½ ê°ì§€
    is_local = os.environ.get('RENDER') is None  # RenderëŠ” ìë™ìœ¼ë¡œ RENDER í™˜ê²½ë³€ìˆ˜ ì„¤ì •
    host = '127.0.0.1' if is_local else '0.0.0.0'
    port = int(os.environ.get('PORT', 5001))
    debug = is_local
    
    print(f"ğŸ“ ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†: http://{host}:{port}")
    print(f"ğŸ”§ í™˜ê²½: {'ë¡œì»¬ ê°œë°œ' if is_local else 'Render ë°°í¬'}")
    print("="*50 + "\n")
